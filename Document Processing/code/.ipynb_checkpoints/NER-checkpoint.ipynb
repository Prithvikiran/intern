{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a07cf8c-ffd2-4284-a0c4-796a5517b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp=spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f606551-3c74-4654-909f-4ecd6e012a77",
   "metadata": {},
   "source": [
    "BASIC FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4805ec02-6bcc-4cb2-b7b3-98b5fe738514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \" Hi this is Prithvi kiran \"\n",
    "doc=nlp(text)\n",
    "type(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abf3a83-0a8b-47d7-aedf-64b69140d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Hi\n",
      "this\n",
      "is\n",
      "Prithvi\n",
      "kiran\n"
     ]
    }
   ],
   "source": [
    "for token in doc :\n",
    "    print(token)\n",
    "spacy.explain('PERSON')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d45dcf0-cdf3-463b-8b77-fe07569adac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi this is Prithvi kiran\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bcee03e-e777-4aa7-ad8b-6104f1568fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attr'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.ent_type_\n",
    "token.head\n",
    "token.ent_iob_\n",
    "token.dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd79882-7458-4245-83dc-4eba4047535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb13e537-aec6-486e-a376-2ae7fc4c45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ddff299-cfff-4d78-8188-17369bbd9f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Hi this is \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Prithvi kiran\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sentence,style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0140f35e-310e-40ec-8fbd-2f318239b542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence[0].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0464ac1f-107f-4611-99a2-305e9c8565ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer=nlp.vocab.strings['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4306c75a-5be0-4839-afbd-9d4673d349be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5439657043933447811"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e202c432-3f6c-4b57-a4a1-8d52f13b7ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5de01-c40b-4c70-94e1-d2967dfb444d",
   "metadata": {},
   "source": [
    "DOCUMENT SIMILARITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "981cba7d-15f8-4d6d-85c6-faf6aa3d1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/gvhz2ks54ds4gc95v5bfv_7m0000gn/T/ipykernel_2403/2221835283.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  doc1.similarity(doc2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7698947588297396"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1=nlp(\"Hi this is Prithvi Kiran\")\n",
    "doc2=nlp(\"I am Prithvi Kiran\")\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763c365-c03c-4a0c-8936-ccd550272fde",
   "metadata": {},
   "source": [
    "The EntityRuler is added to the pipeline. It allows for rule-based entity recognition using patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
